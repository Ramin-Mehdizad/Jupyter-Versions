{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Created on Feb 20, 2020\n",
    "#\n",
    "# @author: Ramin Mehdizad Tekiyeh\n",
    "#\n",
    "# This code is written in Python 3.7.4 , Spyder 3.3.6\n",
    "#==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# This module contains all the Classes that are used in the main code\n",
    "#=============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# importing standard classes\n",
    "#==============================================================================\n",
    "import logging\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# importing module codes\n",
    "#==============================================================================\n",
    "import ModVar as Var\n",
    "import ModFunc as Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this class creates Binary ID3 Class\n",
    "#==============================================================================\n",
    "class Bin_ID3:\n",
    "    \n",
    "    # initializing class instance parameters\n",
    "    def __init__(self,X_train, y_train, dep, max_dep=10):\n",
    "        self.X_trn=X_train\n",
    "        self.y_trn=y_train\n",
    "        self.depth=dep\n",
    "        self.max_depth=max_dep\n",
    "    \n",
    "    # this function extracts y labels items\n",
    "    def My_Extract_y_Labels(self,y):\n",
    "        Labels_list=list()\n",
    "        for _,j in enumerate(y):\n",
    "            if j not in Labels_list: Labels_list.append(j)\n",
    "        return Labels_list\n",
    "\n",
    "    # this function partitions x data\n",
    "    def partition(self,x):\n",
    "        V=list()\n",
    "        dict_partitioned=dict()\n",
    "        for _ ,xx in enumerate(x):\n",
    "            if xx not in V: V.append(int(xx))\n",
    "        \n",
    "        for i in range(len(V)):\n",
    "            indices_list=list()\n",
    "            for j, xx in enumerate(x):\n",
    "                if xx==V[i]: indices_list.append(j)\n",
    "            dict_partitioned[V[i]]= indices_list \n",
    "        return dict_partitioned\n",
    "\n",
    "    # this function calculates the entropy\n",
    "    def entropy(self,x):\n",
    "        x_partitioned=self.partition(x)\n",
    "        if len(x_partitioned)==1:\n",
    "            print('!!!!!!--- Ent=0 ---!!!!!!')\n",
    "            return 0\n",
    "        elif len(x_partitioned)==3:\n",
    "            print('!!! Be careful: not binary partitioning !!!')\n",
    "            return\n",
    "        elif len(x_partitioned)==2:\n",
    "            Ent,n_Tot=0,len(x)\n",
    "            keys=list(x_partitioned.keys())\n",
    "            n=[len(x_partitioned[keys[0]]),len(x_partitioned[keys[1]])]\n",
    "            for i in range(2):\n",
    "                Pi=n[i]/n_Tot\n",
    "                Ent=Ent-Pi*np.log2(Pi)\n",
    "            return Ent\n",
    "       \n",
    "    # this function calcuates the information gain \n",
    "    def Info_Gain(self,attr_no,attr_val):\n",
    "        Ent_S=self.entropy(self.y_trn)\n",
    "        if Var.FlagPrintCalcDetails: print('Ent_S in start of Info_Gain calc is:\\n',Ent_S)\n",
    "        \n",
    "        print('\\n\\n========  New Info_Gain Calc =========')\n",
    "        print('attr_no   is:  ',attr_no)\n",
    "        print('attr_val   is:  ',attr_val)\n",
    "        \n",
    "        # initialize info_gain\n",
    "        info_gain=Ent_S\n",
    "\n",
    "        x_partitioned=self.partition(self.X_trn[:,attr_no])\n",
    "        if Var.FlagPrintCalcDetails: print('x_partitioned is: ', x_partitioned)\n",
    "        \n",
    "        if len(x_partitioned)==1:\n",
    "            # it means all values are the same so we check if this value\n",
    "            # is equal to attr_val or not\n",
    "            if self.X_trn[0,attr_no]==attr_val:\n",
    "                # Info_gain = Ent(s)- 0 - 0\n",
    "                return info_gain\n",
    "            else:\n",
    "                # it means that this pair does not apply for X_trn in this level\n",
    "                return 0\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            n_Tot=len(self.X_trn[:,attr_no])\n",
    "            \n",
    "            # may be attr_val is not a value in that attribute\n",
    "            # so no info gain cab ne obtained by that\n",
    "            if attr_val not in list(x_partitioned.keys()):\n",
    "                return 0\n",
    "            \n",
    "            Val_ID=x_partitioned[attr_val]\n",
    "            if Var.FlagPrintCalcDetails: print('Val_ID   is:  ',Val_ID)\n",
    "            n_Val=len(Val_ID)\n",
    "            if Var.FlagPrintCalcDetails: print('n_Val  is:  ',n_Val)\n",
    "            \n",
    "            NotVal_ID=[i for i in range(n_Tot) if i not in Val_ID]\n",
    "            if Var.FlagPrintCalcDetails: print('NotVal_ID   is:  ',NotVal_ID)\n",
    "            n_NotVal=n_Tot-n_Val\n",
    "            if Var.FlagPrintCalcDetails: print('n_NotVal  is:  ',n_NotVal)\n",
    "            \n",
    "            # initialize and check if all vals are equal\n",
    "            y_Sv_if_S=list()\n",
    "            y_NotSv_if_S=list()\n",
    "            \n",
    "            # if len()==0 or len()=0\n",
    "            y_Sv_if_S=[int(self.y_trn[i]) for i in Val_ID]\n",
    "            if Var.FlagPrintCalcDetails: print('y_Sv_if_S  is:  ',y_Sv_if_S)\n",
    "            Ent_Sv=self.entropy(y_Sv_if_S)\n",
    "            if Var.FlagPrintCalcDetails: print('Ent_Sv   is:  ',Ent_Sv)\n",
    "            \n",
    "            y_NotSv_if_S=[int(self.y_trn[i]) for i in NotVal_ID]\n",
    "            if Var.FlagPrintCalcDetails: print('y_NotSv_if_S  is:  ',y_NotSv_if_S)\n",
    "            Ent_NotSv=self.entropy(y_NotSv_if_S)\n",
    "            if Var.FlagPrintCalcDetails: print('Ent_NotSv   is:  ',Ent_NotSv)\n",
    "            \n",
    "            info_gain=info_gain-n_Val/n_Tot*Ent_Sv-n_NotVal/n_Tot*Ent_NotSv\n",
    "            if Var.FlagPrintCalcDetails: print('info_gain of this pair   is:  ',info_gain)\n",
    "                \n",
    "            return info_gain\n",
    "\n",
    "    # this function defines the majority of label items\n",
    "    def y_MajorityLabel(self,y):\n",
    "        \n",
    "        self.y_Labels_list=self.My_Extract_y_Labels(y)\n",
    "        print('y_Labels_list is: ', self.y_Labels_list)\n",
    "        \n",
    "        if len(self.y_Labels_list)==1:\n",
    "            lbl=int(y[0])\n",
    "        elif len(self.y_Labels_list)==2:\n",
    "            # we return majority label\n",
    "            L1=int(self.y_Labels_list[0])\n",
    "            L2=int(self.y_Labels_list[1])\n",
    "            n1,n2=0,0\n",
    "            if Var.FlagPrintCalcDetails: print('len(y) is:  ', len(y))\n",
    "            for i in range(len(y)):\n",
    "                if y[i]==L1: n1+=1\n",
    "                if y[i]==L2: n2+=1\n",
    "            if Var.FlagPrintCalcDetails: print('n1 is:  ',n1) \n",
    "            if Var.FlagPrintCalcDetails: print('n2 is:  ',n2)\n",
    "            if n1 > n2: \n",
    "                lbl=int(L1)\n",
    "            elif  n1==n2 :\n",
    "                lbl=int(L1)\n",
    "            else:\n",
    "                lbl=int(L2)\n",
    "        \n",
    "        print('y majority is:  ',str(lbl))        \n",
    "        return lbl  \n",
    "    \n",
    "    # this function call the training function   \n",
    "    def fit(self):\n",
    "        self.TrainedTree=self.fitt()\n",
    "        \n",
    "    # this function does the training\n",
    "    def fitt(self):    \n",
    "        self.depth=self.depth+1\n",
    "        print('\\n\\n<<<<----------id3 depth of: '+str(self.depth)+' staretd---------->>>>')\n",
    "        \n",
    "        # extract class labels\n",
    "        self.y_Labels_list=self.My_Extract_y_Labels(self.y_trn)\n",
    "        \n",
    "        print('No of Data in this ID3 is:   ', len(self.y_trn))\n",
    "        \n",
    "        #--------------- Base Case: ending conditions\n",
    "        if self.depth > self.max_depth:\n",
    "            print('max n_iter reached')\n",
    "            return self.y_MajorityLabel(self.y_trn)\n",
    "        else:\n",
    "            if len(Var.attr_val_pair_list) ==0:\n",
    "                print('\\n All pairs are used up')\n",
    "                return  self.y_MajorityLabel(self.y_trn)\n",
    "            else: \n",
    "                # I put the following if so that it wont continue into info-gain\n",
    "                # function and avoid any possible errors\n",
    "                if len(self.y_Labels_list)==1:\n",
    "                    return  self.y_MajorityLabel(self.y_trn)\n",
    "                else:\n",
    "                    #--------------- Recursive Case: \n",
    "                    self.Trained=1\n",
    "                    # clac info gain of all pairs \n",
    "                    Info_Gain_list=list()\n",
    "                    for i in range(len(Var.attr_val_pair_list)):\n",
    "                    # for i in [0]:\n",
    "                        attr_no=Var.attr_val_pair_list[i][0]\n",
    "                        attr_val=Var.attr_val_pair_list[i][1]\n",
    "                        info_gain=self.Info_Gain(attr_no,attr_val)\n",
    "                        Info_Gain_list.append(info_gain)\n",
    "                    if Var.FlagPrintCalcDetails: print('\\n Info_Gain_list is:  \\n', Info_Gain_list)\n",
    "                    \n",
    "                    # select best info gain and best pair\n",
    "                    max_info_gain=0\n",
    "                    best_pair_ID=0\n",
    "                    if len(Var.attr_val_pair_list)==1:\n",
    "                        max_info_gain=Info_Gain_list[0]\n",
    "                        best_pair_ID=0\n",
    "                    else:\n",
    "                        for i in range(len(Var.attr_val_pair_list)):\n",
    "                            if Info_Gain_list[i] > max_info_gain:\n",
    "                                max_info_gain=Info_Gain_list[i]\n",
    "                                best_pair_ID=i\n",
    "                                \n",
    "                    if Var.FlagPrintCalcDetails: print('max_info_gain is:   ',max_info_gain)            \n",
    "                    if Var.FlagPrintCalcDetails: print('best attr pair ID is:   ',best_pair_ID)\n",
    "                    \n",
    "                    # the following means we wont get any gain if we continue\n",
    "                    # the process\n",
    "                    if max_info_gain==0:\n",
    "                        del(Var.attr_val_pair_list[best_pair_ID])\n",
    "                        return self.y_MajorityLabel(self.y_trn)\n",
    "                \n",
    "                    # selected feature and value\n",
    "                    Sel_Feat=Var.attr_val_pair_list[best_pair_ID][0]\n",
    "                    Sel_Val=Var.attr_val_pair_list[best_pair_ID][1]  \n",
    "                    \n",
    "                    # True leaf\n",
    "                    Tuple_True=(Sel_Feat, Sel_Val , True)\n",
    "                    \n",
    "                    # False leaf\n",
    "                    Tuple_False=(Sel_Feat, Sel_Val , False)\n",
    "                    if Var.FlagPrintCalcDetails: print('tuples are: ',Tuple_True,Tuple_False)\n",
    "                    \n",
    "                    # now we split data into True and False to continue recursion process\n",
    "                    x_partitioned=self.partition(self.X_trn[:,Sel_Feat])\n",
    "                    ID_True=list(x_partitioned[Sel_Val])\n",
    "                    ID_False=list()\n",
    "                    for i, k in x_partitioned.items():\n",
    "                        if i != Sel_Val:\n",
    "                            ID_False=ID_False+list(x_partitioned[i])\n",
    "                            \n",
    "                    # it is better to sort\n",
    "                    ID_True=np.sort(ID_True)\n",
    "                    ID_False=np.sort(ID_False)\n",
    "                    \n",
    "                    if Var.FlagPrintCalcDetails: print('ID_True is: ',ID_True)\n",
    "                    if Var.FlagPrintCalcDetails: print('ID_False: ',ID_False)\n",
    "              \n",
    "                    if len(ID_True)==0 or len(ID_False)==0:\n",
    "                        return self.y_MajorityLabel(self.y_trn)\n",
    "                \n",
    "                    # extract true dataset        \n",
    "                    X_trn_True=self.X_trn[ID_True,:]\n",
    "                    y_trn_True=self.y_trn[ID_True]\n",
    "                    # extract false dataset\n",
    "                    X_trn_False=self.X_trn[ID_False,:]\n",
    "                    y_trn_False=self.y_trn[ID_False]\n",
    "                    \n",
    "                    if Var.FlagPrintSplitData: print('X_trn_True is: ',X_trn_True)\n",
    "                    if Var.FlagPrintSplitData: print('y_trn_True: ',y_trn_True)\n",
    "                    \n",
    "                    if Var.FlagPrintSplitData: print('X_trn_False is: ',X_trn_False)\n",
    "                    if Var.FlagPrintSplitData: print('y_trn_False: ',y_trn_False)\n",
    "                   \n",
    "                    # eliminate the calculated pair\n",
    "                    del(Var.attr_val_pair_list[best_pair_ID])\n",
    "\n",
    "                    # create tree dictionary\n",
    "                    Tree= {Tuple_True:Bin_ID3(X_trn_True, y_trn_True, self.depth, max_dep=Var.MaxDepth).fitt(),\n",
    "                        Tuple_False:Bin_ID3(X_trn_False, y_trn_False, self.depth, max_dep=Var.MaxDepth).fitt()}\n",
    "                    \n",
    "                    print('Tree is:  \\n', Tree)\n",
    "                    \n",
    "                    return Tree\n",
    "     \n",
    "    # this functions callthe predicting function                \n",
    "    def predict(self,x):\n",
    "        tre=self.TrainedTree\n",
    "        return self.pred(x,tre)\n",
    "        \n",
    "    # this function does the prediction\n",
    "    def pred(cls,x,tre):\n",
    "        # because we dont want to pass self and we want to extract tree as \n",
    "        # tree and also we need to use the pred function as recursive one,\n",
    "        # we pass cls to use this function but not the self instance.\n",
    "        key1=list(tre.keys())[0]\n",
    "        attr=key1[0]\n",
    "        val=key1[1]\n",
    "        \n",
    "        if x[attr]==val:\n",
    "            tuple1=(attr,val,True)\n",
    "            lbl=tre[tuple1]\n",
    "        else:\n",
    "            tuple1=(attr,val,False)\n",
    "            lbl=tre[tuple1]\n",
    "            \n",
    "        if type(lbl) is dict:\n",
    "            tre=lbl\n",
    "            return cls.pred(x,tre)\n",
    "        else:\n",
    "            return lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this class defines logging events and results into *.log file\n",
    "#        \n",
    "# Note:\n",
    "#     All the methods and logging data are created in the methods of this class\n",
    "#     Then the logging action is done in the main code\n",
    "#==============================================================================\n",
    "class LogClass():\n",
    "    \n",
    "    # initializing class instance parameters\n",
    "    def __init__(self):\n",
    "        # initialize\n",
    "        self.logger=logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        self.formatter=logging.Formatter('%(message)s')\n",
    "        self.filehandler=logging.FileHandler('Log.log')\n",
    "        self.filehandler.setFormatter(self.formatter)\n",
    "        self.logger.addHandler(self.filehandler)\n",
    "        self.splitterLen=84\n",
    "        self.splitterChar='*'\n",
    "        self.EndSep=self.splitterChar*self.splitterLen\n",
    "        \n",
    "    # this method performs the format of logging for each log action    \n",
    "    def LogFrmt(self,n):\n",
    "        if n=='M':\n",
    "            self.formatter=logging.Formatter(' %(message)s')\n",
    "            self.filehandler.setFormatter(self.formatter)\n",
    "        elif n=='LM':\n",
    "            self.formatter=logging.Formatter('%(levelname)s: %(message)s')\n",
    "            self.filehandler.setFormatter(self.formatter)\n",
    "        elif n=='TLM':\n",
    "            self.formatter=logging.Formatter('%(acstime)s: %(levelname)s: %(message)s')\n",
    "            self.filehandler.setFormatter(self.formatter)\n",
    "    \n",
    "    # this method logs ParsedData\n",
    "    def ParsedData(self,n):\n",
    "        self.LogFrmt(n)\n",
    "        title=' Data Entered by User '\n",
    "        sp=self.splitterChar*(round((self.splitterLen-len(title))/2))\n",
    "        self.logger.info(sp+title+sp)\n",
    "        self.logger.info('')\n",
    "        self.logger.info('  Results Path         ='+ os.getcwd())\n",
    "        self.logger.info('  Save Plots           ='+ Var.args.SavePlot)\n",
    "        self.logger.info('  Create Log File      ='+ Var.args.logFile)\n",
    "        self.logger.info(self.EndSep)\n",
    "    \n",
    "    # this method logs start of the main\n",
    "    def ProgStart(self,n):\n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('')\n",
    "        title=' Main Program Started '\n",
    "        sp=self.splitterChar*(round((self.splitterLen-len(title))/2))\n",
    "        self.logger.info(sp+title+sp)\n",
    "        self.logger.info('')\n",
    "        self.logger.info('')\n",
    "     \n",
    "    # this method logs the system on which the analysis if performed  \n",
    "    def SysSpec(self,sysinfo,n):\n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('')\n",
    "        self.logger.info('')\n",
    "        title=' COMPUTER SPEC '\n",
    "        sp=self.splitterChar*round((self.splitterLen-len(title))/2)\n",
    "        self.logger.info(sp+title+sp)\n",
    "        self.logger.info('Data analsys is done on the system with following spec:\\n')  \n",
    "        for i,[a1,a2] in enumerate(Var.sysinfo):\n",
    "            DataStartChar=30\n",
    "            len1=len(Var.sysinfo[i][0])\n",
    "            Arrow='-'*(DataStartChar-len1)+'> '\n",
    "            self.logger.info(Var.sysinfo[i][0]+Arrow+Var.sysinfo[i][1])\n",
    "        self.logger.info(self.EndSep)\n",
    "\n",
    "    # this method logs start of a new loop for a treewith specific max depth    \n",
    "    def NewTreStarted(self,maxdepth,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('')\n",
    "        self.logger.info('New Decision Tree calculation with max depth={0} started'.format(maxdepth))\n",
    "        \n",
    "    # this method logs new classifier object created    \n",
    "    def NewTreClassifierCreated(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('New Tree class created')\n",
    "\n",
    "    # this method logs new tree trained    \n",
    "    def NewTreTrained(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('Decision Tree trained')\n",
    "        \n",
    "    # this method logs tree plotted to console     \n",
    "    def TrePlottedToConsole(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('Tree plotted toconsole')\n",
    "\n",
    "    # this method logs tree plotted by graphviz     \n",
    "    def TreePlottedByGraphviz(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('Tree plotted by graphviz and the plot saved')\n",
    "        \n",
    "    # this method logs train error calculated     \n",
    "    def TrainErrorCalculated(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('Train error calculated') \n",
    "        \n",
    "    # this method logs test error calculated     \n",
    "    def TestErrorCalculated(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('Test error calculated')\n",
    "        \n",
    "    # this method logs accuracy plot created     \n",
    "    def AccuracyPlotCreated(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('Test error calculated')\n",
    "        \n",
    "    # this method logs accuracy plot created     \n",
    "    def ProgTerminated(self,n):    \n",
    "        self.LogFrmt(n)\n",
    "        self.logger.info('')\n",
    "        self.logger.info('Program terminated successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

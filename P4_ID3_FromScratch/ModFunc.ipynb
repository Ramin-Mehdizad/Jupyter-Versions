{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# Created on Feb 25, 2020\n",
    "#\n",
    "# @author: Ramin Mehdizad Tekiyeh\n",
    "#\n",
    "# This code is written in Python 3.7.4 , Spyder 3.3.6\n",
    "#==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# importing standard classes\n",
    "#==============================================================================\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import graphviz\n",
    "    print(\"!!! Graphviz imported successfully !!!\")\n",
    "except:\n",
    "    print(\"!!! Graphviz couldn't be imported !!!\")\n",
    "    Var.graphviz_import_ID=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# importing module codes\n",
    "#==============================================================================\n",
    "import ModVar as Var\n",
    "import Main as Mn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function asks user input data\n",
    "#==============================================================================  \n",
    "def Input_Data_Message():\n",
    "    \n",
    "    print('')\n",
    "    print('|===========================================================')\n",
    "    print('|  ==> To run the code with default values, just press Enter')\n",
    "    print('|  ==> Otherwise:')\n",
    "    print('|  ==> Enter the parameters as following format:')\n",
    "    print('|')\n",
    "    print('| -l 0 -p 0')\n",
    "    print('|')\n",
    "    print('|  ==> To get help, type \"-h\" and press Enter')\n",
    "    print('|  ==> To exit program, type \"Q\" and press Enter')\n",
    "    print('|===========================================================')\n",
    "    \n",
    "    Var.str_input=input('  Enter parameters: ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function asks user input data\n",
    "#==============================================================================\n",
    "def Call_Parsed_Input():\n",
    "    \n",
    "    # create parse class\n",
    "    parser1 = argparse.ArgumentParser(add_help=True,prog='Decision Tree ID3 Scratch',\n",
    "             description='* This program is based on ID3 scratch code')\n",
    "    \n",
    "    # set program version\n",
    "    parser1.add_argument('-v','--version',action='version',\n",
    "                        version='%(prog)s 1.0')\n",
    "\n",
    "    # whether to create log file or not\n",
    "    parser1.add_argument('-l', '--log', action='store',\n",
    "                         default='1', dest='logFile', choices=['0', '1'],\n",
    "                         help='0: Dont create logfile     1: create logfile')\n",
    "    \n",
    "    # whether to print calculations\n",
    "    parser1.add_argument('-p', '--PrintCalculations', action='store', \n",
    "                         default='1',  dest='PrintCalculations', choices=['0', '1'],\n",
    "                         help='0: Dont Print Calculations     1: Print Calculations')\n",
    "    \n",
    "    \n",
    "    # indicates when to exit while loop\n",
    "    entry=False\n",
    "    while entry==False:\n",
    "        # initialize\n",
    "        ParsErr=0\n",
    "        FileErr=0\n",
    "        makedirErr=0\n",
    "        \n",
    "        # --------------in this section we try to parse successfully-----------\n",
    "        # function to call input data from command line    \n",
    "        Input_Data_Message()\n",
    "        \n",
    "        # user wanted to continue with default values\n",
    "        if Var.str_input=='':\n",
    "            Var.args=parser1.parse_args()\n",
    "            # exit while loop\n",
    "            entry=True\n",
    "        elif Var.str_input.upper()=='Q':\n",
    "            # exit script\n",
    "            sys.exit()\n",
    "        else:\n",
    "            entry=True\n",
    "            ParsErr=0\n",
    "            try:\n",
    "                args=parser1.parse_args(Var.str_input.split(' '))\n",
    "            except:\n",
    "                entry=False\n",
    "                ParsErr=1\n",
    "                \n",
    "        #----------------------------------------------------------------------\n",
    "             \n",
    "        if Var.args.PrintCalculations=='1':\n",
    "            Var.FlagPrintSplitData=True\n",
    "                            \n",
    "        #----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function asks user input data\n",
    "#==============================================================================  \n",
    "def Read_Data():\n",
    "\n",
    "    df=pd.read_csv('dataset.csv')\n",
    "    \n",
    "    print(df,end='\\n\\n')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================\n",
    "def encod(df_data):\n",
    "    \n",
    "    # a list of attr names\n",
    "    Var.column_names=list(df_data.columns)\n",
    "    num_columns=len(Var.column_names)\n",
    "    if Var.FlagPrintSplitData: print('num of columns is:',num_columns)\n",
    "    \n",
    "    # number of data record\n",
    "    num_data=len(df_data[Var.column_names[0]])\n",
    "    if Var.FlagPrintSplitData: print('num of data is:',num_data)\n",
    "    \n",
    "    # extract list of each column unique values\n",
    "    Var.column_unique_values=list()\n",
    "    for i in range(num_columns):\n",
    "        vals=list()\n",
    "        for j in range(num_data):\n",
    "            if df_data.iloc[j][i] not in vals:\n",
    "                vals.append(df_data.iloc[j][i])\n",
    "        Var.column_unique_values.append(vals)\n",
    "        \n",
    "    # encode values of each column\n",
    "    encoded_data=list()\n",
    "    for i in range(num_columns): \n",
    "        encoded_column_vals=list()\n",
    "        for j in range(num_data):\n",
    "            for n in range(len(Var.column_unique_values[i])):\n",
    "                if df_data.iloc[j][i]==Var.column_unique_values[i][n]:\n",
    "                    encoded_column_vals.append(n)\n",
    "        encoded_data.append(encoded_column_vals)\n",
    "    encoded_data=np.array(encoded_data).T\n",
    "    \n",
    "    X_trn=encoded_data[:,0:-1]\n",
    "    y_trn=encoded_data[:,-1]\n",
    "    \n",
    "    return(X_trn,y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================\n",
    "def Labels_Unique_List(y):\n",
    "    Labels_list=list()\n",
    "    for _,j in enumerate(y):\n",
    "        if j not in Labels_list:\n",
    "            Labels_list.append(j)\n",
    "    return Labels_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================\n",
    "def y_Majority(y):\n",
    "    if Var.FlagPrintSplitData: print('entered y_Majority func')\n",
    "    Labels_list=Labels_Unique_List(y)\n",
    "    if Var.FlagPrintSplitData: print('Labels_list is: ', Labels_list)\n",
    "    \n",
    "    if len(Labels_list)==1:\n",
    "        lbl=Var.column_unique_values[-1][int(y[0])]\n",
    "    elif len(Labels_list)==2:\n",
    "        # we return majority label\n",
    "        L1=int(Labels_list[0])\n",
    "        L2=int(Labels_list[1])\n",
    "        if Var.FlagPrintSplitData: \n",
    "            print('L1 is:  ',L1) \n",
    "            print('L2 is:  ',L2)\n",
    "        n1=0\n",
    "        n2=0\n",
    "        if Var.FlagPrintSplitData: print('len(y) is:  ', len(y))\n",
    "        for i in range(len(y)):\n",
    "            if y[i]==L1: n1+=1\n",
    "            if y[i]==L2: n2+=1\n",
    "        if Var.FlagPrintSplitData: \n",
    "            print('n1 is:  ',n1) \n",
    "            print('n2 is:  ',n2)\n",
    "        if n1 > n2: \n",
    "            lbl=Var.column_unique_values[-1][int(L1)]\n",
    "        elif  n1==n2 :\n",
    "            lbl=Var.column_unique_values[-1][int(L1)]\n",
    "        else:\n",
    "            lbl=Var.column_unique_values[-1][int(L2)]\n",
    "    \n",
    "    if Var.FlagPrintSplitData: print('y majority is:  ',str(lbl))        \n",
    "    return lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================\n",
    "def partition(x):\n",
    "    # here we extract unique values\n",
    "    unique_vals=list()\n",
    "    dict_partitioned=dict()\n",
    "    for _ ,xx in enumerate(x):\n",
    "        if xx not in unique_vals:\n",
    "            unique_vals.append(xx)\n",
    "            \n",
    "    # here we fill dict for unique_vals\n",
    "    for i in range(len(unique_vals)):\n",
    "        indices_list=list()\n",
    "        for j, xx in enumerate(x):\n",
    "            if xx==unique_vals[i]: indices_list.append(j)\n",
    "        dict_partitioned[unique_vals[i]]= indices_list \n",
    "\n",
    "    return dict_partitioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================\n",
    "def entropy(x):\n",
    "    x_partitioned=partition(x)\n",
    "    if len(x_partitioned)==1:\n",
    "        if Var.FlagPrintSplitData: print('!!!!!!--- Ent=0 ---!!!!!!')\n",
    "        return 0\n",
    "    elif len(x_partitioned)==3:\n",
    "        if Var.FlagPrintSplitData: \n",
    "            print('!!! Be careful: not binary partitioning !!!')\n",
    "        return\n",
    "    elif len(x_partitioned)==2:\n",
    "        Ent=0\n",
    "        keys=list(x_partitioned.keys())\n",
    "        n_Tot=len(x)\n",
    "        n=[len(x_partitioned[keys[0]]),len(x_partitioned[keys[1]])]\n",
    "        for i in range(2):\n",
    "            Pi=n[i]/n_Tot\n",
    "            Ent=Ent-Pi*np.log2(Pi)\n",
    "        return Ent    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================\n",
    "def Info_Gain(attr_no,X_trn,y_trn):\n",
    "    \n",
    "    # global column_values, column_names, column_unique_values\n",
    "    # global num_columns, ID_list\n",
    "    \n",
    "    if Var.FlagPrintSplitData: \n",
    "        print('\\n\\n--------  New Info_Gain Calc --------')\n",
    "        print('current attr_no for calc of Info_Gain is :  ',attr_no)\n",
    "    \n",
    "    Ent_S=entropy(y_trn)\n",
    "    if Var.FlagPrintSplitData: print('Ent_S is :  ',Ent_S)\n",
    "    \n",
    "    # initialize info_gain\n",
    "    info_gain=Ent_S\n",
    "\n",
    "    x_partitioned=partition(X_trn[:,attr_no])\n",
    "    if Var.FlagPrintSplitData: print('x_partitioned is: ', x_partitioned)\n",
    "    \n",
    "    if len(x_partitioned)==1:\n",
    "        # it means that by use of this attr all data falls in the same group\n",
    "        # so we get no info_gain\n",
    "        # return info_gain\n",
    "        return 0\n",
    "    else:\n",
    "        # total num of data\n",
    "        n_Tot=len(X_trn[:,0])\n",
    "        \n",
    "        for _ , indice in x_partitioned.items():\n",
    "            y_if_Sv=[y_trn[i] for i in indice]\n",
    "            if Var.FlagPrintSplitData: print('y_if_Sv  ',y_if_Sv)\n",
    "            info_gain=info_gain-(len(y_if_Sv)/n_Tot)*entropy(y_if_Sv)\n",
    "            \n",
    "        if Var.FlagPrintSplitData: \n",
    "            print('info_gain  of this attr is:  ',info_gain)\n",
    "            print('-------------------------------------')\n",
    "\n",
    "        return info_gain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================\n",
    "def id3(X_trn, y_trn, depth, max_depth=10):\n",
    "    \n",
    "    # depth incremented\n",
    "    depth=depth+1\n",
    "    if Var.FlagPrintSplitData: \n",
    "        print('\\n\\n<<<<=======id3 depth of: '+str(depth)+' staretd=======>>>>')\n",
    "    \n",
    "    # extract class labels\n",
    "    Labels_list=Labels_Unique_List(y_trn)\n",
    "    if Var.FlagPrintSplitData: \n",
    "        print('Labels_list   is:  ',Labels_list)\n",
    "        print('No of Data in this id3 depth is:   ', len(y_trn))\n",
    "\n",
    "    #-------------------- Base Case: ending conditions-------------------------\n",
    "    if depth > max_depth:\n",
    "        if Var.FlagPrintSplitData: print('max n_iter reached')\n",
    "        return y_Majority(y_trn)\n",
    "    else:\n",
    "        if len(Var.attrs_list) ==0:\n",
    "            if Var.FlagPrintSplitData: print('\\n All attributes are used up')\n",
    "            return y_Majority(y_trn)\n",
    "        else: \n",
    "            # I put the following 'if' so that it wont continue into info-gain\n",
    "            # function and avoid any possible errors\n",
    "            if len(Labels_list)==1:\n",
    "                return y_Majority(y_trn)\n",
    "            else:\n",
    "                \n",
    "                #-------------------- Recursive Case: -------------------------\n",
    "                    \n",
    "                # choose best attr by calc of info-gains-----------------------  \n",
    "                # it means only one attribute is left so we choose it\n",
    "                Info_Gain_list=list()\n",
    "                for i in range(len(Var.attrs_list)):\n",
    "                    # attr_no=attrs_list[i]\n",
    "                    info_gain=Info_Gain(Var.attrs_list[i],X_trn,y_trn)\n",
    "                    Info_Gain_list.append(info_gain)\n",
    "                if Var.FlagPrintSplitData: \n",
    "                    print('\\n Info_Gain_list of current depth is:  \\n',\n",
    "                                              Info_Gain_list,end='\\n\\n')\n",
    "                \n",
    "                # select best info gain and best attribute\n",
    "                max_info_gain=0\n",
    "                best_attr_ID=0\n",
    "                # check if only one attr is left\n",
    "                if len(Var.attrs_list)==1:\n",
    "                    max_info_gain=Info_Gain_list[0]\n",
    "                    best_attr_ID=0\n",
    "                else:\n",
    "                    for i in range(len(Var.attrs_list)):\n",
    "                        if Info_Gain_list[i] > max_info_gain:\n",
    "                            max_info_gain=Info_Gain_list[i]\n",
    "                            best_attr_ID=Var.attrs_list[i]\n",
    "                if Var.FlagPrintSplitData:             \n",
    "                    print('max_info_gain is:   ',max_info_gain,end='\\n\\n')            \n",
    "                    print('best attr ID is:   ',best_attr_ID,end='\\n\\n')\n",
    "                #--------------------------------------------------------------\n",
    "                    \n",
    "                \n",
    "                # the following means we wont get any gain if we continue\n",
    "                # the process\n",
    "                if max_info_gain==0:\n",
    "                    return y_Majority(y_trn)\n",
    "            \n",
    "                # calc tuple for tree dict\n",
    "                tuples_list=list()\n",
    "                for _, v in enumerate(Var.column_unique_values[best_attr_ID]):\n",
    "                    tuples_list.append((Var.column_names[best_attr_ID],v))\n",
    "                \n",
    "                # print tuples created for tree dict\n",
    "                print('tuples_list is:   ',tuples_list,end='\\n\\n')\n",
    "                \n",
    "                # now we split data based on selected attribute to continue \n",
    "                # recursion process\n",
    "                x_partitioned=partition(X_trn[:,best_attr_ID])\n",
    "                if Var.FlagPrintSplitData: \n",
    "                    print('x_partitioned is: ', x_partitioned)\n",
    "                ID_Split_list=list()\n",
    "                curr_num_data=X_trn.shape[0]\n",
    "                \n",
    "                if Var.FlagPrintSplitData: \n",
    "                    print('curr_num_data is:',curr_num_data,end='\\n\\n')\n",
    "                    \n",
    "                for i in range(len(Var.column_unique_values[best_attr_ID])):\n",
    "                    curr_val_ID=list()\n",
    "                    \n",
    "                    for j in range(curr_num_data):\n",
    "                        if X_trn[j,best_attr_ID]==i:\n",
    "                            curr_val_ID.append(j)\n",
    "                    ID_Split_list.append(curr_val_ID)\n",
    "                    \n",
    "                if Var.FlagPrintSplitData: \n",
    "                    print('ID_Split_list is:',ID_Split_list,end='\\n\\n')\n",
    "                \n",
    "                # I double check it here for any unforseen problems\n",
    "                if len(ID_Split_list)==0:\n",
    "                    return y_Majority(y_trn)\n",
    "            \n",
    "                # extract split x and y        \n",
    "                X_trn_split_list=list()\n",
    "                y_trn_split_list=list()\n",
    "                for _, v in enumerate(ID_Split_list):\n",
    "                    xxx=X_trn[v,:]\n",
    "                    yyy=y_trn[v]\n",
    "                    X_trn_split_list.append(xxx)\n",
    "                    y_trn_split_list.append(yyy)\n",
    "                    \n",
    "                if Var.FlagPrintSplitData: print('split x in this depth is: \\n',\n",
    "                                X_trn_split_list,end='\\n\\n')\n",
    "                if Var.FlagPrintSplitData: print('split y in this depth is: \\n',\n",
    "                                y_trn_split_list,end='\\n\\n')\n",
    "               \n",
    "                # eliminate the calculated attribute\n",
    "                index=np.where(Var.attrs_list==best_attr_ID)[0]\n",
    "                Var.attrs_list=np.delete(Var.attrs_list, index)\n",
    "\n",
    "                # initialize tree\n",
    "                Trained_Tree=dict()\n",
    "                \n",
    "                for i in range(len(ID_Split_list)):\n",
    "                    Trained_Tree[tuples_list[i]]=id3(X_trn_split_list[i],\n",
    "                           y_trn_split_list[i], depth, max_depth=Var.MaxDepth)\n",
    "                \n",
    "                print('Trained_Tree is:  \\n', Trained_Tree)\n",
    "                \n",
    "                return Trained_Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================    \n",
    "def Print_Tree_to_Console(tree, depth=0):\n",
    "\n",
    "    if depth==0:\n",
    "        print('\\n\\n&&&&&&&&&&&&&&&& === TREE === &&&&&&&&&&&&&&&&&&')\n",
    "        for _ in range(4):\n",
    "            print('              ||               ||')\n",
    "\n",
    "        print('         \\\\\\        //     \\\\\\        //')\n",
    "        print('          \\\\\\      //       \\\\\\      //')\n",
    "        print('           \\\\\\    //         \\\\\\    //')\n",
    "        print('            \\\\\\  //           \\\\\\  //')\n",
    "        print('             \\\\\\//             \\\\\\//')\n",
    "        print('              \\\\/               \\\\/')\n",
    "        print('\\nTREE')\n",
    "\n",
    "    for index, split_criterion in enumerate(tree):\n",
    "        sub_trees=tree[split_criterion]\n",
    "\n",
    "        # Print the current node: split criterion\n",
    "        print('|\\t'*depth,end='')\n",
    "        print('+---[@@@@: {0} = {1} ]'.format(split_criterion[0], \n",
    "                                split_criterion[1]))\n",
    "\n",
    "        # Print the children\n",
    "        if type(sub_trees) is dict:\n",
    "            Print_Tree_to_Console(sub_trees,depth+1)\n",
    "        else:\n",
    "            print('|\\t'*(depth+1),end='')\n",
    "            print('+---[LABEL ===> {0}]'.format(sub_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# this function encods data\n",
    "#==============================================================================    \n",
    "def Create_dot_str(tree, dot_string='', node_counter=0, depth=0):\n",
    "\n",
    "    print('\\n=========== id3 recursion  ===========')\n",
    "    print('entered dot_string is:  \\n', dot_string)\n",
    "    print('entered node_counter is:  ', node_counter)\n",
    "\n",
    "    node_counter += 1       # Running index of node ids across recursion\n",
    "    cur_node_id = node_counter  # Node id of this node\n",
    "    \n",
    "    print('node_counter   is:  ', node_counter)\n",
    "    print('cur_node_id   is:  ', cur_node_id)\n",
    "    \n",
    "\n",
    "    # when depth=0, the first line of dot_string is added here\n",
    "    if depth == 0:\n",
    "        dot_string += 'digraph TREE {\\n'\n",
    "\n",
    "    for key, value in tree.items():\n",
    "        \n",
    "        sub_trees = value\n",
    "        attribute_name = key[0]\n",
    "        attribute_value = key[1]\n",
    "\n",
    "        print('for this for loop we have: >>>')\n",
    "        print('sub_trees   is:  ', sub_trees)\n",
    "        print('attribute_name   is:  ', attribute_name)\n",
    "        print('attribute_value   is:  ', attribute_value)\n",
    "        \n",
    "\n",
    "        if type(sub_trees) is dict:\n",
    "            \n",
    "            print('type dict')\n",
    "\n",
    "            # data before recursion\n",
    "            print('cur_node_id   is:  ', cur_node_id)      \n",
    "            new_node_id=node_counter+1\n",
    "            print('node_counter   is:  ', node_counter)\n",
    "            print('new_node_id   is:  ', new_node_id)\n",
    "\n",
    "\n",
    "            print('dot_string BEFORE RECURSION  is:  \\n', dot_string)\n",
    "            \n",
    "            dot_string, cur_node_id, node_counter  = Create_dot_str(\\\n",
    "                sub_trees, dot_string, node_counter, depth+1 )\n",
    "            \n",
    "            # create old node\n",
    "            dot_string += 'node{0} [label=\"{1}\"];\\n'.format(cur_node_id, attribute_name)\n",
    "                \n",
    "            # create new node\n",
    "            dot_string += 'node{0} [label=\"{1}\"];\\n'.format(new_node_id, '')\n",
    "            \n",
    "            # create new connection\n",
    "            dot_string += 'node{0} -> node{1} [label=\"{2}\"];\\n'.format(cur_node_id, \n",
    "                                        node_counter+1, attribute_value)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            print('if else')\n",
    "\n",
    "  \n",
    "            # increase counter to craete new label node\n",
    "            node_counter+=1\n",
    "            new_node_id=node_counter\n",
    "            \n",
    "            old_node_id=cur_node_id\n",
    "            \n",
    "            print('if else with: cur_node_id={0}, new_node_id={1}'.format(cur_node_id, new_node_id))\n",
    "            \n",
    "            # create current node\n",
    "            dot_string += 'node{0} [label=\"{1}\"];\\n'.format(cur_node_id, attribute_name)\n",
    "            \n",
    "            # create new node\n",
    "            dot_string += 'node{0} [label=\"{1}\"];\\n'.format(new_node_id, sub_trees)\n",
    "            \n",
    "            # create connection\n",
    "            dot_string += 'node{0} -> node{1} [label=\"{2}\"];\\n'.format(cur_node_id,\n",
    "                                            new_node_id, attribute_value)\n",
    "            \n",
    "            print('dot_string   is:  \\n', dot_string)\n",
    "\n",
    "    \n",
    "    # when depth=0, the last line of dot_string is added here\n",
    "    if depth == 0:\n",
    "        dot_string += '}\\n'\n",
    "    \n",
    "    return dot_string, cur_node_id, node_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Uses GraphViz to render a dot file\n",
    "#==============================================================================\n",
    "def render_dot_file(dot_string, save_file, image_format='png'):\n",
    "\n",
    "    if type(dot_string).__name__ != 'str':\n",
    "        raise TypeError('visualize() requires a string representation of a decision tree.\\nUse tree.export_graphviz()'\n",
    "                        'for decision trees produced by scikit-learn and to_graphviz() for decision trees produced by'\n",
    "                        'your code.\\n')\n",
    "\n",
    "    # # Set path to your GraphViz executable here\n",
    "    try:\n",
    "        graph = graphviz.Source(dot_string)\n",
    "        graph.format = image_format\n",
    "        graph.render(save_file, view=True) \n",
    "    except:\n",
    "        print('Error using graphviz') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

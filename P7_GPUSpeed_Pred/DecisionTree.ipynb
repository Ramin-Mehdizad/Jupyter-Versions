{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created on Mon Mar  9 22:09:02 2020\n",
    "#\n",
    "#@author: Ramin Mehdizad Tekiyeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we import data set from csv file\n",
    "df_original=pd.read_csv(\"ComputerSpeedData.csv\")\n",
    "df=df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating GPU run time average\n",
    "df[\"RunF\"]=(df[\"Run1 (ms)\"]+df[\"Run2 (ms)\"]+df[\"Run3 (ms)\"]+df[\"Run4 (ms)\"])/4\n",
    "# dropping 4 run timecolumns\n",
    "df=df.drop(columns=['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'])\n",
    "df['RunF'].mean()\n",
    "# putting average run time in a new target column\n",
    "df['RunF_binary']=np.where(df['RunF']>=100,1,0)\n",
    "dff_original=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test sets\n",
    "train,test=train_test_split(dff_original,test_size=0.3,random_state=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are data frames\n",
    "x_train=train.iloc[:,0:14]\n",
    "y_train=train.iloc[:,-1]\n",
    "x_test=test.iloc[:,0:14]\n",
    "y_test=test.iloc[:,-1]\n",
    "print('x_train.shape[0] is:     ',x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------use decision tree--------------------\n",
    "# here we use decision tree model on the whole data set\n",
    "# defining decision tree classifier\n",
    "clf=DecisionTreeClassifier(criterion='gini')\n",
    "# training the model\n",
    "clf=clf.fit(x_train,y_train)\n",
    "# applying model on both train and test data\n",
    "y_pred_train=clf.predict(x_train)\n",
    "y_pred_test=clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy_score(y_train,y_pred_train) is: \\n\",\n",
    "      accuracy_score(y_train,y_pred_train),end='\\n\\n')\n",
    "print(\"accuracy_score(y_test,y_pred_test) is: \\n\",\n",
    "      accuracy_score(y_test,y_pred_test),end='\\n\\n')\n",
    "print(\"onfusion_matrix(y_pred_train,y_train) is: \\n\",\n",
    "      confusion_matrix(y_pred_train,y_train),end='\\n\\n')\n",
    "print(\"confusion_matrix(y_pred_test,y_test) is: \\n\",\n",
    "      confusion_matrix(y_pred_test,y_test),end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function defines decision tree models with different depths\n",
    "# and then applies it on the data set and calculates accuracy\n",
    "def dtmetrics (x_tr,x_ts,y_tr,y_ts,max_depth):\n",
    "    # initializing the lists\n",
    "    train_results=[]\n",
    "    test_results=[]\n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "    for max_depth in max_depths:\n",
    "        # defining model\n",
    "       dt=DecisionTreeClassifier(max_depth=max_depth)\n",
    "       # treaining the model\n",
    "       dt.fit(x_tr,y_tr)\n",
    "       # predicting train and test data\n",
    "       train_pred=dt.predict(x_tr)\n",
    "       test_pred=dt.predict(x_ts) \n",
    "       fpr,tpr,thresholds=roc_curve(y_tr,train_pred)\n",
    "       roc_auc=auc(fpr,tpr)\n",
    "       # Add auc score to previous train results\n",
    "       train_results.append(roc_auc)\n",
    "       y_pred=dt.predict(x_ts)\n",
    "       fpr,tpr,thresholds=roc_curve(y_ts,y_pred)\n",
    "       roc_auc=auc(fpr,tpr)\n",
    "       # Add auc score to previous test results\n",
    "       test_results.append(roc_auc)\n",
    "       train_acc=accuracy_score(y_tr,train_pred)\n",
    "       test_acc=accuracy_score(y_ts,test_pred)\n",
    "       train_accuracy.append(train_acc)\n",
    "       test_accuracy.append(test_acc)\n",
    "    return test_accuracy,train_accuracy,test_results,train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a series of tree depth to be used in calissifier models\n",
    "max_depths=np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22])\n",
    "# use the function to calculate accuracy\n",
    "test_accuracy,train_accuracy,test_AUC,train_AUC=dtmetrics(x_tr=x_train,x_ts=x_test,y_tr=y_train,y_ts=y_test,max_depth=max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results\n",
    "plt.plot(max_depths,train_AUC,'b',label='Train AUC')\n",
    "plt.plot(max_depths,test_AUC,'r',label='Test AUC')\n",
    "plt.legend(loc='best',frameon=False)\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.title(\"AUC VS Tree Depth for Original Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results\n",
    "plt.plot(max_depths,train_accuracy,'b',label='Train Accuracy')\n",
    "plt.plot(max_depths,test_accuracy,'r',label='Test Accuracy')\n",
    "plt.legend(loc='best',frameon=False)\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.title(\"Accuracy VS Tree Depth for Original Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------feature selection by svm method----------------\n",
    "# In this section SVM method is used for feature selection\n",
    "\n",
    "\n",
    "# define model for feature selection\n",
    "m=LinearSVC(C=0.000002,penalty='l1',dual=False)\n",
    "# fitting the model on the data set\n",
    "clf=m.fit(x_train,y_train)\n",
    "s=SelectFromModel(clf,prefit=True)\n",
    "Xnew=s.transform(x_train)\n",
    "print(\"Xnew\",Xnew[0:5,:],end='\\n\\n')\n",
    "print(\"features 0,1,3,4,8 are the most effective\")\n",
    "\n",
    "# dropping the unimportant features from dataset\n",
    "#df2=df_original.drop(['MWG','NWG','KWG','MDIMC','NDIMC','MDIMA','NDIMB','KWI','VWM','VWN','STRM','STRN','SA','SB'])\n",
    "df2=df_original.drop(columns=['KWG','MDIMA','NDIMB','KWI','VWN','STRM','STRN','SA','SB'])\n",
    "\n",
    "# calculatiing GPU run time average\n",
    "df2[\"RunF\"]=(df2[\"Run1 (ms)\"]+df2[\"Run2 (ms)\"]+ df2[\"Run3 (ms)\"]+df2[\"Run4 (ms)\"])/4\n",
    "df2=df2.drop(columns=['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'])\n",
    "# putting average runtime in a new target column\n",
    "df2['RunF'].mean()\n",
    "#df2['RunF_binary'] = np.where(df2['RunF']>=217.5, 1, 0)\n",
    "df2['RunF_binary']=np.where(df2['RunF']>=100,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are data frames for reduced features\n",
    "x_train_RD=train.iloc[:,0:5]\n",
    "y_train_RD=train.iloc[:,-1]\n",
    "x_test_RD=test.iloc[:,0:5]\n",
    "y_test_RD=test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying decision tree classifier on the train data set\n",
    "clf=DecisionTreeClassifier(criterion='gini')\n",
    "clf=clf.fit(x_train_RD,y_train_RD)\n",
    "y_pred_train_RD=clf.predict(x_train_RD)\n",
    "y_pred_test_RD=clf.predict(x_test_RD)\n",
    "\n",
    "print(\"accuracy_score(y_train_RD,y_pred_trai_RDn) is: \\n\",\n",
    "      accuracy_score(y_train_RD,y_pred_train_RD),end='\\n\\n')\n",
    "print(\"accuracy_score(y_test_RD,y_pred_test_RD) is: \\n\",\n",
    "      accuracy_score(y_test_RD,y_pred_test_RD),end='\\n\\n')\n",
    "print(\"onfusion_matrix( y_pred_train_RD,y_train_RD) is: \\n\",\n",
    "      confusion_matrix( y_pred_train_RD,y_train_RD),end='\\n\\n')\n",
    "print(\"confusion_matrix( y_pred_test_RD,y_test_RD) is: \\n\",\n",
    "      confusion_matrix( y_pred_test_RD,y_test_RD),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy and AUC of train and test data\n",
    "test_accuracy_RD,train_accuracy_RD,test_AUC_RD,train_AUC_RD=dtmetrics(x_tr=x_train_RD,x_ts=x_test_RD,y_tr=y_train_RD,y_ts=y_test_RD,max_depth=max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting AUC versus tree depth\n",
    "plt.figure(30)\n",
    "plt.plot(max_depths,train_AUC_RD,'b',label='Train AUC')\n",
    "plt.plot(max_depths,test_AUC_RD,'r',label='Test AUC')\n",
    "plt.legend(loc='best',frameon=False)\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.title(\"AUC VS Tree Depth for Selected Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting Accuracy versus tree depth\n",
    "plt.figure(30)\n",
    "plt.plot(max_depths,train_accuracy_RD,'b',label='Train Accuracy')\n",
    "plt.plot(max_depths,test_accuracy_RD,'r',label='Test Accuracy')\n",
    "plt.legend(loc='best',frameon=False)\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.title(\"Accuracy VS Tree Depth for Selected Features\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

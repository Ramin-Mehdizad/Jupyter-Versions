{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import threading\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode\n",
    "from sklearn.decomposition import FastICA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import random_projection\n",
    "\n",
    "Flag_2Dplot=1\n",
    "Flag_3Dplot=1\n",
    "num_red_Feat=10\n",
    "n_ExtraTrees=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- read data -  for classification\n",
    "\n",
    "random_state=np.random.randint(low = 0, high = 100)\n",
    "        \n",
    "# in this section we read scsvfile and import dataset\n",
    "df=pd.read_csv(\"ComputerSpeedData.csv\")\n",
    "\n",
    "# here we calculate average of 4 run time\n",
    "df[\"RunF\"]=(df[\"Run1 (ms)\"]+df[\"Run2 (ms)\"]+df[\"Run3 (ms)\"]+df[\"Run4 (ms)\"])/4\n",
    "\n",
    "# here we drop run time columns and insert the average amount into a new column\n",
    "df_clas=df.drop(columns=['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'])\n",
    "df_clas=df_clas.drop(columns=['RunF'])\n",
    "\n",
    "# categorize based in mean\n",
    "avg=df['RunF'].mean()\n",
    "df['RunF_binary']=np.where(df['RunF']>=avg,1,0)\n",
    "df_y=pd.DataFrame(df['RunF_binary'])\n",
    "\n",
    "df=df.drop(columns=['RunF','RunF_binary'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X=df_clas.values\n",
    "X=scaler.fit_transform(X)\n",
    "y=df_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           Feature importance by Trees\n",
    "forest = ExtraTreesClassifier(n_estimators=30, random_state=0)\n",
    "\n",
    "forest.fit(X,y)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "a=(forest.estimators_)\n",
    "print('\\n a[0].feature_importances_ is: ', a[0].feature_importances_)\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest by Feature Names\n",
    "attr_labels=df_clas.columns\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances by Feature Names\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), attr_labels, rotation=70)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest by Feature Indices\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances by Feature Indices\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices, rotation=70)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- read data -  for clustering\n",
    "random_state=np.random.randint(low = 0, high = 100)\n",
    "        \n",
    "# in this section we read scsvfile and import dataset\n",
    "df=pd.read_csv(\"ComputerSpeedData.csv\")\n",
    "\n",
    "# here we calculate average of 4 run time\n",
    "df[\"RunF\"]=(df[\"Run1 (ms)\"]+df[\"Run2 (ms)\"]+df[\"Run3 (ms)\"]+df[\"Run4 (ms)\"])/4\n",
    "\n",
    "# here we drop run time columns and insert the average amount into a new column\n",
    "df_clus=df.drop(columns=['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'])\n",
    "scaler = StandardScaler()\n",
    "X_Clus=scaler.fit_transform(df_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       dimension reduced data\n",
    "\n",
    "pca = PCA(n_components=num_red_Feat)\n",
    "X_pca=np.array(pca.fit_transform(X_Clus))\n",
    "print(X_pca.shape)\n",
    "\n",
    "ica = FastICA(n_components=num_red_Feat, random_state=0)\n",
    "X_ica = ica.fit_transform(X_Clus)\n",
    "\n",
    "rp = random_projection.GaussianRandomProjection(n_components=num_red_Feat)\n",
    "X_rp = rp.fit_transform(X_Clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_PCA feature importance\n",
    "forest = ExtraTreesClassifier(n_estimators=n_ExtraTrees, random_state=0)\n",
    "forest.fit(X_pca,y)\n",
    "importances = forest.feature_importances_\n",
    "a=(forest.estimators_)\n",
    "print('\\n a[0].feature_importances_ is: ', a[0].feature_importances_)\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices_PCA = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_pca.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices_PCA[f], importances[indices_PCA[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances of X_pca data\")\n",
    "plt.bar(range(X_pca.shape[1]), importances[indices_PCA],\n",
    "       color=\"r\", yerr=std[indices_PCA], align=\"center\")\n",
    "plt.xticks(range(X_pca.shape[1]), indices, rotation=70)\n",
    "plt.xlim([-1, X_pca.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_ICA feature importance\n",
    "forest = ExtraTreesClassifier(n_estimators=30, random_state=0)\n",
    "forest.fit(X_ica,y)\n",
    "importances = forest.feature_importances_\n",
    "a=(forest.estimators_)\n",
    "print('\\n a[0].feature_importances_ is: ', a[0].feature_importances_)\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices_ICA = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_ica.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices_ICA[f], importances[indices_ICA[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances of X_ica data\")\n",
    "plt.bar(range(X_ica.shape[1]), importances[indices_ICA],\n",
    "       color=\"r\", yerr=std[indices_ICA], align=\"center\")\n",
    "plt.xticks(range(X_ica.shape[1]), indices_ICA, rotation=70)\n",
    "plt.xlim([-1, X_ica.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rp feature importance\n",
    "forest = ExtraTreesClassifier(n_estimators=30, random_state=0)\n",
    "forest.fit(X_rp,y)\n",
    "importances = forest.feature_importances_\n",
    "a=(forest.estimators_)\n",
    "print('\\n a[0].feature_importances_ is: ', a[0].feature_importances_)\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices_RP = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_rp.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices_RP[f], importances[indices_RP[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances of X_rp data\")\n",
    "plt.bar(range(X_rp.shape[1]), importances[indices_RP],\n",
    "       color=\"r\", yerr=std[indices_RP], align=\"center\")\n",
    "plt.xticks(range(X_rp.shape[1]), indices_RP, rotation=70)\n",
    "plt.xlim([-1, X_rp.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         KMeans of original data\n",
    "kmeans=KMeans(n_clusters=2)\n",
    "clusters=kmeans.fit_predict(X_Clus)\n",
    "\n",
    "acc=accuracy_score(y,clusters)\n",
    "if acc<0.5: acc=1-acc\n",
    "print('Accuracy of KMeans of original data is: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Flag_2Dplot:\n",
    "    # plot original classification\n",
    "    plt.figure()\n",
    "    plt.scatter(X_Clus[:,0],X_Clus[:,1], c=y, s=40, cmap='RdYlBu')\n",
    "    plt.title('Real Classification')\n",
    "    plt.xlabel('MWG')\n",
    "    plt.ylabel('NWG')\n",
    "    \n",
    "    # plot kmeans clustering\n",
    "    plt.figure()\n",
    "    plt.scatter(X_Clus[:,0],X_Clus[:,1], c=clusters, s=40, cmap='RdYlBu')\n",
    "    plt.title('KMeans Clusters of original data')\n",
    "    plt.xlabel('MWG')\n",
    "    plt.ylabel('NWG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3D by 3 most important feature\n",
    "if Flag_3Dplot:\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(X_Clus[:, 0], X_Clus[:, 1], X_Clus[:, 4],\n",
    "                c=clusters.astype(np.float),  \n",
    "                edgecolor=None)\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Feat 0')\n",
    "    ax.set_ylabel('Feat 1')\n",
    "    ax.set_zlabel('Feat 4')\n",
    "    ax.set_title('KMeans Clusters of original data')\n",
    "    ax.dist = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM on original data\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# covariance_type{‘full’ (default), ‘tied’, ‘diag’, ‘spherical’}\n",
    "model=GaussianMixture(n_components=2,\n",
    "              covariance_type= 'diag' , max_iter=100, random_state=0)\n",
    "\n",
    "clusters=model.fit_predict(X_Clus)\n",
    "\n",
    "acc=accuracy_score(y,clusters)\n",
    "if acc<0.5: acc=1-acc\n",
    "print('Accuracy of EM on original data is: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kmeaans clustering\n",
    "if Flag_2Dplot:\n",
    "    plt.figure()\n",
    "    plt.scatter(X_Clus[:,0],X_Clus[:,1], c=clusters, s=40, cmap='RdYlBu')\n",
    "    plt.title('EM Clusters of original data')\n",
    "    plt.xlabel('MWG')\n",
    "    plt.ylabel('NWG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3D by 3 most important feature of originaal data\n",
    "if Flag_3Dplot:\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(X_Clus[:, 0], X_Clus[:, 1], X_Clus[:, 4],\n",
    "                c=clusters.astype(np.float),  \n",
    "                edgecolor=None)\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Feat 0')\n",
    "    ax.set_ylabel('Feat 1')\n",
    "    ax.set_zlabel('Feat 4')\n",
    "    ax.set_title('EM Clusters of original data')\n",
    "    ax.dist = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_KMeans_PCA = list()\n",
    "acc_KMeans_ICA = list()\n",
    "acc_KMeans_rp = list()\n",
    "\n",
    "sse_KMeans_PCA = list()\n",
    "sse_KMeans_ICA = list()\n",
    "sse_KMeans_rp = list()\n",
    "\n",
    "acc_EM_PCA = list()\n",
    "acc_EM_ICA = list()\n",
    "acc_EM_rp = list()\n",
    "\n",
    "mse_EM_PCA = list()\n",
    "mse_EM_ICA = list()\n",
    "mse_EM_rp = list()\n",
    "\n",
    "\n",
    "n_list=[14,13,12,11,10,9,8,7,6,5,4]\n",
    "for k in n_list:\n",
    "    print('\\n========iteration no is: ========= \\n', k)\n",
    "    \n",
    "    pca = PCA(n_components=k)\n",
    "    X_pca=np.array(pca.fit_transform(X_Clus))\n",
    "    \n",
    "    ica = FastICA(n_components=k, random_state=0)\n",
    "    X_ica = ica.fit_transform(X_Clus)\n",
    "    \n",
    "    rp = random_projection.GaussianRandomProjection(n_components=k)\n",
    "    X_rp = rp.fit_transform(X_Clus)\n",
    "    \n",
    "    # extract feature importance of each reduced dataset\n",
    "    # X_PCA feature importance\n",
    "    forest = ExtraTreesClassifier(n_estimators=n_ExtraTrees, random_state=0)\n",
    "    forest.fit(X_pca,y)\n",
    "    importances = forest.feature_importances_\n",
    "    \n",
    "    indices_PCA = np.argsort(importances)[::-1]\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # X_ICA feature importance\n",
    "    forest = ExtraTreesClassifier(n_estimators=30, random_state=0)\n",
    "    forest.fit(X_ica,y)\n",
    "    importances = forest.feature_importances_\n",
    "    \n",
    "    indices_ICA = np.argsort(importances)[::-1]\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    # X_rp feature importance\n",
    "    forest = ExtraTreesClassifier(n_estimators=30, random_state=0)\n",
    "    forest.fit(X_rp,y)\n",
    "    importances = forest.feature_importances_\n",
    "   \n",
    "    indices_RP = np.argsort(importances)[::-1]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #%%         KMeans of PCA data\n",
    "    kmeans=KMeans(n_clusters=2)\n",
    "    clusters=kmeans.fit_predict(X_pca)\n",
    "    sse_KMeans_PCA.append( kmeans.inertia_)\n",
    "    acc=accuracy_score(y,clusters)\n",
    "    \n",
    "    if acc<0.5: acc=1-acc\n",
    "    acc_KMeans_PCA.append(acc)\n",
    "    print('Accuracy of KMeans on PCA data is: ',acc)\n",
    "    \n",
    "    # plot kmeans clustering\n",
    "    if Flag_2Dplot:\n",
    "        if k==4:\n",
    "            plt.figure()\n",
    "            plt.scatter(X_pca[:,indices_PCA[0]],X_pca[:,indices_PCA[1]],\n",
    "                        c=clusters, s=40, cmap='RdYlBu')\n",
    "            plt.title('KMeans Clusters of PCA data')\n",
    "            plt.xlabel('Feat {}'.format(indices_PCA[0]))\n",
    "            plt.ylabel('Feat {}'.format(indices_PCA[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot 3D by 3 most important feature of X_pca\n",
    "    if Flag_3Dplot:\n",
    "        if k==4:\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = Axes3D(fig)\n",
    "            ax.scatter(X_pca[:, 0], X_pca[:, 3], X_pca[:, 2],\n",
    "                        c=clusters.astype(np.float),  \n",
    "                        edgecolor=None)\n",
    "            ax.w_xaxis.set_ticklabels([])\n",
    "            ax.w_yaxis.set_ticklabels([])\n",
    "            ax.w_zaxis.set_ticklabels([])\n",
    "            ax.set_xlabel('Feat {}'.format(indices_PCA[0]))\n",
    "            ax.set_ylabel('Feat {}'.format(indices_PCA[1]))\n",
    "            ax.set_zlabel('Feat {}'.format(indices_PCA[2]))\n",
    "            ax.set_title('KMeans Clusters of X_pca data')\n",
    "            ax.dist = 12\n",
    "    \n",
    "    \n",
    "    #%%\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #%%         KMeans of ICA data\n",
    "    kmeans=KMeans(n_clusters=2)\n",
    "    clusters=kmeans.fit_predict(X_ica)\n",
    "    sse_KMeans_ICA.append(  kmeans.inertia_)\n",
    "    acc=accuracy_score(y,clusters)\n",
    "    \n",
    "    if acc<0.5: acc=1-acc\n",
    "    acc_KMeans_ICA.append(acc)\n",
    "    print('Accuracy of KMeans on ICA data is: ',acc)\n",
    "    \n",
    "    # plot kmeans clustering\n",
    "    if Flag_2Dplot:\n",
    "        if k==4:\n",
    "            plt.figure()\n",
    "            plt.scatter(X_ica[:,indices_ICA[0]],X_ica[:,indices_ICA[1]], \n",
    "                        c=clusters, s=40, cmap='RdYlBu')\n",
    "            plt.title('KMeans Clusters of ICA data')\n",
    "            plt.xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            plt.ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "    \n",
    "    \n",
    "    # plot 3D by 3 most important feature of X_pca\n",
    "    if Flag_3Dplot:\n",
    "        if k==4:\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = Axes3D(fig)\n",
    "            ax.scatter(X_ica[:, indices_ICA[0]], X_ica[:, indices_ICA[1]],\n",
    "                       X_ica[:, indices_ICA[2]], c=clusters.astype(np.float),  \n",
    "                        edgecolor=None)\n",
    "            ax.w_xaxis.set_ticklabels([])\n",
    "            ax.w_yaxis.set_ticklabels([])\n",
    "            ax.w_zaxis.set_ticklabels([])\n",
    "            ax.set_xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            ax.set_ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "            ax.set_zlabel('Feat {}'.format(indices_ICA[2]))\n",
    "            ax.set_title('KMeans Clusters of X_ica data')\n",
    "            ax.dist = 12\n",
    "    \n",
    "    #%%\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #%%         KMeans of rp data\n",
    "    kmeans=KMeans(n_clusters=2)\n",
    "    clusters=kmeans.fit_predict(X_rp)\n",
    "    sse_KMeans_rp.append(  kmeans.inertia_)\n",
    "    acc=accuracy_score(y,clusters)\n",
    "    \n",
    "    if acc<0.5: acc=1-acc\n",
    "    acc_KMeans_rp.append(acc)\n",
    "    print('Accuracy of KMeans on rp data is: ',acc)\n",
    "    \n",
    "    # plot kmeans clustering\n",
    "    if Flag_2Dplot:\n",
    "        if k==4:\n",
    "            plt.figure()\n",
    "            plt.scatter(X_rp[:,indices_ICA[0]],X_rp[:,indices_ICA[1]], \n",
    "                        c=clusters, s=40, cmap='RdYlBu')\n",
    "            plt.title('KMeans Clusters of rp data')\n",
    "            plt.xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            plt.ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "    \n",
    "    \n",
    "    # plot 3D by 3 most important feature of X_pca\n",
    "    if Flag_3Dplot:\n",
    "        if k==4:\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = Axes3D(fig)\n",
    "            ax.scatter(X_rp[:, indices_ICA[0]], X_rp[:, indices_ICA[1]],\n",
    "                       X_rp[:, indices_ICA[2]], c=clusters.astype(np.float),  \n",
    "                        edgecolor=None)\n",
    "            ax.w_xaxis.set_ticklabels([])\n",
    "            ax.w_yaxis.set_ticklabels([])\n",
    "            ax.w_zaxis.set_ticklabels([])\n",
    "            ax.set_xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            ax.set_ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "            ax.set_zlabel('Feat {}'.format(indices_ICA[2]))\n",
    "            ax.set_title('KMeans Clusters of X_rp data')\n",
    "            ax.dist = 12\n",
    "    \n",
    "    #%%\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #%%                    EM   on PCA data\n",
    "    \n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    \n",
    "    # covariance_type{‘full’ (default), ‘tied’, ‘diag’, ‘spherical’}\n",
    "    model=GaussianMixture(n_components=2,\n",
    "                  covariance_type= 'diag' , max_iter=100, random_state=0)\n",
    "    \n",
    "    clusters=model.fit_predict(X_pca)\n",
    "    covariances = model.covariances_\n",
    "    mse_EM_PCA.append( np.diag(covariances))\n",
    "    acc=accuracy_score(y,clusters)\n",
    "    \n",
    "    if acc<0.5: acc=1-acc\n",
    "    acc_EM_PCA.append(acc)\n",
    "    print('Accuracy of EM on PCA data is: ',acc)\n",
    "    \n",
    "    # plot kmeaans clustering\n",
    "    if Flag_2Dplot:\n",
    "        if k==4:\n",
    "            plt.figure()\n",
    "            plt.scatter(X_pca[:,indices_PCA[0]],X_pca[:,indices_PCA[1]],\n",
    "                        c=clusters, s=40, cmap='RdYlBu')\n",
    "            plt.title('EM Clusters of PCA data')\n",
    "            plt.xlabel('Feat {}'.format(indices_PCA[0]))\n",
    "            plt.ylabel('Feat {}'.format(indices_PCA[1]))\n",
    "    \n",
    "    \n",
    "    # plot 3D by 3 most important feature of X_pca data\n",
    "    if Flag_3Dplot:\n",
    "        if k==4:\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = Axes3D(fig)\n",
    "            ax.scatter(X_pca[:, indices_PCA[0]], X_pca[:, indices_PCA[1]],\n",
    "                       X_pca[:, indices_PCA[2]], c=clusters.astype(np.float),  \n",
    "                        edgecolor=None)\n",
    "            ax.w_xaxis.set_ticklabels([])\n",
    "            ax.w_yaxis.set_ticklabels([])\n",
    "            ax.w_zaxis.set_ticklabels([])\n",
    "            ax.set_xlabel('Feat {}'.format(indices_PCA[0]))\n",
    "            ax.set_ylabel('Feat {}'.format(indices_PCA[1]))\n",
    "            ax.set_zlabel('Feat {}'.format(indices_PCA[2]))\n",
    "            ax.set_title('EM Clusters of X_pca data')\n",
    "            ax.dist = 12\n",
    "    \n",
    "    #%%\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #%%                    EM   on ICA data\n",
    "    \n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    \n",
    "    # covariance_type{‘full’ (default), ‘tied’, ‘diag’, ‘spherical’}\n",
    "    model=GaussianMixture(n_components=2,\n",
    "                  covariance_type= 'diag' , max_iter=100, random_state=0)\n",
    "    \n",
    "    clusters=model.fit_predict(X_ica)\n",
    "    covariances = model.covariances_\n",
    "    mse_EM_ICA.append( np.diag(covariances))\n",
    "    acc=accuracy_score(y,clusters)\n",
    "    \n",
    "    if acc<0.5: acc=1-acc\n",
    "    acc_EM_ICA.append(acc)\n",
    "    print('Accuracy of EM on ICA data is: ',acc)\n",
    "    \n",
    "    # plot kmeaans clustering\n",
    "    if Flag_2Dplot:\n",
    "        if k==4:\n",
    "            plt.figure()\n",
    "            plt.scatter(X_ica[:,indices_ICA[0]],X_ica[:,indices_ICA[1]],\n",
    "                        c=clusters, s=40, cmap='RdYlBu')\n",
    "            plt.title('EM Clusters of ICA data')\n",
    "            plt.xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            plt.ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot 3D by 3 most important feature of X_ica data\n",
    "    if Flag_3Dplot:\n",
    "        if k==4:\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = Axes3D(fig)\n",
    "            ax.scatter(X_ica[:,indices_ICA[0]], X_ica[:, indices_ICA[1]],\n",
    "                       X_ica[:, indices_ICA[2]], c=clusters.astype(np.float),  \n",
    "                        edgecolor=None)\n",
    "            ax.w_xaxis.set_ticklabels([])\n",
    "            ax.w_yaxis.set_ticklabels([])\n",
    "            ax.w_zaxis.set_ticklabels([])\n",
    "            ax.set_xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            ax.set_ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "            ax.set_zlabel('Feat {}'.format(indices_ICA[2]))\n",
    "            ax.set_title('EM Clusters of X_ica data')\n",
    "            ax.dist = 12\n",
    "    \n",
    "    #%%\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #%%                    EM   on rp data\n",
    "    \n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    \n",
    "    # covariance_type{‘full’ (default), ‘tied’, ‘diag’, ‘spherical’}\n",
    "    model=GaussianMixture(n_components=2,\n",
    "                  covariance_type= 'diag' , max_iter=100, random_state=0)\n",
    "    \n",
    "    clusters=model.fit_predict(X_rp)\n",
    "    covariances = model.covariances_\n",
    "    mse_EM_rp.append(  np.diag(covariances))\n",
    "    acc=accuracy_score(y,clusters)\n",
    "    \n",
    "    if acc<0.5: acc=1-acc\n",
    "    acc_EM_rp.append(acc)\n",
    "    print('Accuracy of EM on rp data is: ',acc)\n",
    "    \n",
    "    # plot kmeaans clustering\n",
    "    if Flag_2Dplot:\n",
    "        if k==4:\n",
    "            plt.figure()\n",
    "            plt.scatter(X_rp[:,indices_ICA[0]],X_rp[:,indices_ICA[1]], \n",
    "                        c=clusters, s=40, cmap='RdYlBu')\n",
    "            plt.title('EM Clusters of X_rp data')\n",
    "            plt.xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            plt.ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "    \n",
    "    \n",
    "    # plot 3D by 3 most important feature of X_ica data\n",
    "    if Flag_3Dplot:\n",
    "        if k==4:\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = Axes3D(fig)\n",
    "            ax.scatter(X_rp[:, indices_ICA[0]], X_rp[:, indices_ICA[1]],\n",
    "                       X_rp[:, indices_ICA[2]], c=clusters.astype(np.float),  \n",
    "                        edgecolor=None)\n",
    "            ax.w_xaxis.set_ticklabels([])\n",
    "            ax.w_yaxis.set_ticklabels([])\n",
    "            ax.w_zaxis.set_ticklabels([])\n",
    "            ax.set_xlabel('Feat {}'.format(indices_ICA[0]))\n",
    "            ax.set_ylabel('Feat {}'.format(indices_ICA[1]))\n",
    "            ax.set_zlabel('Feat {}'.format(indices_ICA[2]))\n",
    "            ax.set_title('EM Clusters of X_rp data')\n",
    "            ax.dist = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot SSE of KMeans        \n",
    "plt.figure()\n",
    "plt.plot(n_list,sse_KMeans_PCA,'b-o',label='pca')\n",
    "plt.plot(n_list,sse_KMeans_ICA,'g-o',label='ica')\n",
    "plt.plot(n_list,sse_KMeans_rp,'r-o',label='rp')\n",
    "plt.legend(loc='best')\n",
    "plt.title('SSE of KMeans for different dimensions')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('SSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot acc of KMeans        \n",
    "plt.figure()\n",
    "plt.plot(n_list,acc_KMeans_PCA,'b-o',label='pca')\n",
    "plt.plot(n_list,acc_KMeans_ICA,'g-o',label='ica')\n",
    "plt.plot(n_list,acc_KMeans_rp,'r-o',label='rp')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Accuracy of KMeans for different dimensions')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSE of EM\n",
    "mse_EM_PCA_1=list()\n",
    "mse_EM_ICA_1=list()\n",
    "mse_EM_rp_1=list()\n",
    "for i in range(len(n_list)):\n",
    "    mse_EM_PCA_1.append(mse_EM_PCA[i] [0])\n",
    "    mse_EM_ICA_1.append(mse_EM_ICA[i] [0])\n",
    "    mse_EM_rp_1.append(mse_EM_rp[i] [0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(n_list,mse_EM_PCA_1,'b-o',label='pca')\n",
    "plt.plot(n_list,mse_EM_ICA_1,'g-o',label='ica')\n",
    "plt.plot(n_list,mse_EM_rp_1,'r-o',label='rp')\n",
    "plt.legend(loc='best')\n",
    "plt.title('MSE of EM for different dimensions')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Acc of EM\n",
    "plt.figure()\n",
    "plt.plot(n_list,acc_EM_PCA,'b-o',label='pca')\n",
    "plt.plot(n_list,acc_EM_ICA,'g-o',label='ica')\n",
    "plt.plot(n_list,acc_EM_rp,'r-o',label='rp')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Accuracy of EM for different dimensions')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
